{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, ConfusionMatrixDisplay,homogeneity_score\n",
    "from sklearn.model_selection import GridSearchCV,RepeatedStratifiedKFold,train_test_split,RandomizedSearchCV\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from scipy.stats import randint\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get data \n",
    "# Read in the data\n",
    "dataset = \"partial_database.csv\"\n",
    "df = pd.read_csv(dataset)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "# Decomment this part if you dont have the labels in the csv file\n",
    "# Read class labels\n",
    "f = open(\"labelsDefault.txt\", \"r\")\n",
    "labels=f.read().splitlines()\n",
    "labels.pop(0)\n",
    "\n",
    "# Add y column, which is the target variable\n",
    "df['y'] = list(map(int,labels))\n",
    "\"\"\"\n",
    "\n",
    "# Get X and y\n",
    "Y=df['y']\n",
    "X=df.drop(['y'],axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get dataframe of class 1,2,3,4,5,6,7\n",
    "df1=df.loc[df['y'].isin([1,2,3,4,5,6,7])]\n",
    "Y1=df1['y']\n",
    "X1=df1.drop(['y'],axis=1)\n",
    "\n",
    "#Get dataframe of class 8,9,10\n",
    "df2=df.loc[df['y'].isin([8,9,10])]\n",
    "Y2=df2['y']\n",
    "X2=df2.drop(['y'],axis=1)\n",
    "\n",
    "#Get dataframe of class 11,12,13\n",
    "df3=df.loc[df['y'].isin([11,12,13])]\n",
    "Y3=df3['y']\n",
    "X3=df3.drop(['y'],axis=1)\n",
    "\n",
    "#Get dataframe of class 14,15,16\n",
    "df4=df.loc[df['y'].isin([14,15,16])]\n",
    "Y4=df4['y']\n",
    "X4=df4.drop(['y'],axis=1)\n",
    "\n",
    "#Get dataframe of class 17,18,19\n",
    "df5=df.loc[df['y'].isin([17,18,19])]\n",
    "Y5=df5['y']\n",
    "X5=df5.drop(['y'],axis=1)\n",
    "\n",
    "#Get dataframe of class 20,21,22\n",
    "df6=df.loc[df['y'].isin([20,21,22])]\n",
    "Y6=df6['y']\n",
    "X6=df6.drop(['y'],axis=1)\n",
    "\n",
    "#Train test split\n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(X1, Y1, test_size=0.2, random_state=1)\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X2, Y2, test_size=0.2, random_state=1)\n",
    "X_train3, X_test3, y_train3, y_test3 = train_test_split(X3, Y3, test_size=0.2, random_state=1)\n",
    "X_train4, X_test4, y_train4, y_test4 = train_test_split(X4, Y4, test_size=0.2, random_state=1)\n",
    "X_train5, X_test5, y_train5, y_test5 = train_test_split(X5, Y5, test_size=0.2, random_state=1)\n",
    "X_train6, X_test6, y_train6, y_test6 = train_test_split(X6, Y6, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daito\\miniconda3\\envs\\ML\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1930: FutureWarning: The default value of `n_init` will change from 3 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=3)\n",
      "c:\\Users\\Daito\\miniconda3\\envs\\ML\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1962: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 1280 or by setting the environment variable OMP_NUM_THREADS=4\n",
      "  warnings.warn(\n",
      "c:\\Users\\Daito\\miniconda3\\envs\\ML\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1930: FutureWarning: The default value of `n_init` will change from 3 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=3)\n",
      "c:\\Users\\Daito\\miniconda3\\envs\\ML\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1962: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 1280 or by setting the environment variable OMP_NUM_THREADS=3\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MiniBatchKMeans(n_clusters=17)\n",
      "Split 5\n",
      "purity 0.9283347028766619\n",
      "global purity 0.3486020901374144\n",
      "Split 2\n",
      "purity 0.8021107311268307\n",
      "global purity 0.4001207493599188\n",
      "Split 1\n",
      "purity 0.7134378114227068\n",
      "global purity 0.4429114855181801\n",
      "Split 3\n",
      "purity 0.5833853012924538\n",
      "global purity 0.44364156182546804\n",
      "Split 6\n",
      "purity 0.5698118262705609\n",
      "global purity 0.44841868549466496\n",
      "Split 4\n",
      "purity 0.512830094140746\n",
      "global purity 0.4492822542817939\n"
     ]
    }
   ],
   "source": [
    "#Model loading and fitting\n",
    "search = MiniBatchKMeans()\n",
    "\n",
    "#Model optimization\n",
    "param_grid = {'n_clusters': randint(1, 22),\n",
    "              }\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "search = RandomizedSearchCV(search, param_grid, scoring='homogeneity_score', n_jobs=-1, cv=cv, random_state=1)\n",
    "\n",
    "#Fit the model\n",
    "search.fit(X_train1,y_train1)\n",
    "best_rf = search.best_estimator_\n",
    "\n",
    "print(best_rf)\n",
    "kmeans=MiniBatchKMeans(n_clusters=best_rf.n_clusters)\n",
    "\n",
    "\n",
    "print(\"Split 5\")\n",
    "kmeans.partial_fit(X_train5,y_train5)\n",
    "print(\"purity\",homogeneity_score(y_test5,kmeans.predict(X_test5)))\n",
    "print(\"global purity\",homogeneity_score(Y,kmeans.predict(X)))\n",
    "\n",
    "print(\"Split 2\")\n",
    "kmeans.partial_fit(X_train2,y_train2)\n",
    "print(\"purity\",homogeneity_score(y_test2,kmeans.predict(X_test2)))\n",
    "print(\"global purity\",homogeneity_score(Y,kmeans.predict(X)))\n",
    "\n",
    "print(\"Split 1\")\n",
    "kmeans.partial_fit(X_train1,y_train1)\n",
    "print(\"purity\",homogeneity_score(y_test1,kmeans.predict(X_test1)))\n",
    "print(\"global purity\",homogeneity_score(Y,kmeans.predict(X)))\n",
    "\n",
    "print(\"Split 3\")\n",
    "kmeans.partial_fit(X_train3,y_train3)\n",
    "print(\"purity\",homogeneity_score(y_test3,kmeans.predict(X_test3)))\n",
    "print(\"global purity\",homogeneity_score(Y,kmeans.predict(X)))\n",
    "\n",
    "print(\"Split 6\")\n",
    "kmeans.partial_fit(X_train6,y_train6)\n",
    "print(\"purity\",homogeneity_score(y_test3,kmeans.predict(X_test3)))\n",
    "print(\"global purity\",homogeneity_score(Y,kmeans.predict(X)))\n",
    "\n",
    "print(\"Split 4\")\n",
    "kmeans.partial_fit(X_train4,y_train4)\n",
    "print(\"purity\",homogeneity_score(y_test4,kmeans.predict(X_test4)))\n",
    "print(\"global purity\",homogeneity_score(Y,kmeans.predict(X)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
