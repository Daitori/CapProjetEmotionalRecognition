{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Doc \n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split,StratifiedKFold,RandomizedSearchCV,RepeatedStratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics.cluster import pair_confusion_matrix\n",
    "from sklearn.preprocessing import normalize\n",
    "from memory_profiler import memory_usage\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetLoader():\n",
    "    def __init__(self):\n",
    "        self.df=None\n",
    "        self.X = None\n",
    "        self.y = None\n",
    "        self.X_train = None\n",
    "        self.X_test = None\n",
    "        self.y_train = None\n",
    "        self.y_test = None\n",
    "        self.numbers_of_classes = None\n",
    "        self.classes=None\n",
    "\n",
    "    def read_dataset(self,file_path,separator=',',class_path=None):\n",
    "        df = pd.read_csv(file_path, sep=separator)\n",
    "        self.X = df.copy()\n",
    "        if class_path!=None:\n",
    "            df['class'] = pd.read_csv(class_path)\n",
    "            self.y = df['class']\n",
    "            self.classes=df['class'].unique()\n",
    "            self.numbers_of_classes = len(self.classes)\n",
    "        self.df=df\n",
    "\n",
    "\n",
    "    def normalize(self,features_to_normalize=None): #features_to_normalize is a list of index\n",
    "        if features_to_normalize!=None:\n",
    "            return normalize(self.X[:,features_to_normalize[0]:features_to_normalize[1]])\n",
    "\n",
    "    def select_features(self,features): #features is a list of features [feature1,feature2,...] or [:156]\n",
    "        self.X=self.df.iloc[features]\n",
    "    \n",
    "    def select_classes(self,classes): #classes is a list of classes [class1,class2,...] with len(classes) = len of dataset\n",
    "        self.y = classes\n",
    "        self.classes=np.unique(classes)\n",
    "        self.numbers_of_classes = len(self.classes)\n",
    "        \n",
    "    def split_dataset(self,test_size=0.2): #slit dataset into train and test\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(self.X, self.y, test_size=test_size)\n",
    "    \n",
    "    def split_dataset_class(self,class_to_group): #split dataset into train and test based on class\n",
    "        # Initialize empty lists to store merged sets\n",
    "        X_train_merged, X_test_merged, y_train_merged, y_test_merged = [], [], [], []\n",
    "        for i in class_to_group.values():\n",
    "            df_temp=self.df[self.df['class'].isin(i)]\n",
    "            X_train, X_test, y_train, y_test = train_test_split(df_temp.iloc[:,:-1], df_temp['class'], test_size=0.2)\n",
    "            X_train_merged.append(X_train)\n",
    "            X_test_merged.append(X_test)\n",
    "            y_train_merged.append(y_train)\n",
    "            y_test_merged.append(y_test)\n",
    "\n",
    "        # Merge sets\n",
    "        return X_train_merged, X_test_merged, y_train_merged, y_test_merged\n",
    "    \n",
    "    def split_dataset_data(self,n): #split dataset by data size\n",
    "        X_train_merged,X_test_merged,y_train_merged,y_test_merged=[],[],[],[]\n",
    "        df_copy=self.df.copy()\n",
    "        df_copy.pop('class')\n",
    "        skf=StratifiedKFold(n_splits=n,shuffle=False)\n",
    "        skf.get_n_splits(self.X_train,self.y_train)\n",
    "        for i,(train_index, test_index) in enumerate(skf.split(self.X, self.y)):\n",
    "            X_train_fold=df_copy.iloc[train_index]\n",
    "            Y_train_fold=self.y[train_index]\n",
    "            X_train_merged.append(X_train_fold)\n",
    "            y_train_merged.append(Y_train_fold)\n",
    "\n",
    "            X_test_fold=df_copy.iloc[test_index]\n",
    "            Y_test_fold=self.y[test_index]\n",
    "            X_test_merged.append(X_test_fold)\n",
    "            y_test_merged.append(Y_test_fold)\n",
    "        \n",
    "        return X_train_merged,y_train_merged,X_test_merged,y_test_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelLoader():\n",
    "    def __init__(self):\n",
    "        self.model=None\n",
    "        self.initial_model=None\n",
    "        self.optimizer_model=None\n",
    "        self.optimal_params=None\n",
    "\n",
    "    def set_optimal_params(self,optimal_params):\n",
    "        self.optimal_params=optimal_params\n",
    "\n",
    "    def set_model(self,model):\n",
    "        self.model=model\n",
    "        self.initial_model=model\n",
    "\n",
    "    def reset_model(self):\n",
    "        self.model=self.initial_model\n",
    "\n",
    "    def optimize(self,X_train,y_train,cv=5,scoring='accuracy',n_iter=10):\n",
    "        self.optimizer_model = RandomizedSearchCV(self.model,self.optimal_params,cv=cv,scoring=scoring,n_iter=n_iter)\n",
    "        self.optimizer_model.fit(X_train,y_train)\n",
    "        self.optimal_params = self.optimizer_model.best_params_\n",
    "\n",
    "    def fit_train(self,X_train,y_train):\n",
    "        return memory_usage(( self.model.fit, (X_train,y_train), {}), retval=True)\n",
    "\n",
    "    def partial_fit_train(self,X_train,y_train,classes): # IF model compatible with partial_fit\n",
    "        return memory_usage(( self.model.partial_fit, (X_train,y_train,classes), {}), retval=True)\n",
    "        \n",
    "    def predict(self,X_test):\n",
    "        return self.model.predict(X_test)\n",
    "    \n",
    "    def score(self,X_test,y_test):\n",
    "        return self.model.score(X_test,y_test)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get data \n",
    "loader = DatasetLoader()\n",
    "loader.read_dataset('partial_database.csv',class_path='labelsDefault.txt',separator=',')\n",
    "loader.split_dataset()\n",
    "\n",
    "#Normalize data, if not already normalized\n",
    "print(np.shape(loader.X_train),np.shape(loader.X_test),np.shape(loader.y_train),np.shape(loader.y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13178294573643412\n",
      "0.05138339920948617\n",
      "0.0\n",
      "0.07509881422924901\n",
      "0.06306306306306306\n",
      "0.08596837944664032\n",
      "0.0\n",
      "0.09189723320158102\n",
      "0.0\n",
      "0.10375494071146245\n",
      "0.0\n",
      "0.10869565217391304\n"
     ]
    }
   ],
   "source": [
    "#Model\n",
    "model=ModelLoader()\n",
    "model.set_model(MLPClassifier(random_state=1))\n",
    "\n",
    "#Optimization \n",
    "\n",
    "param = {'hidden_layer_sizes': [(100,100,100), (100,100,100,100,100), (100,100,100,100,100,100,100,100,100,100)],\n",
    "              'max_iter':[300,500,1000]}\n",
    "cv = RepeatedStratifiedKFold(n_splits=22, n_repeats=3, random_state=1)\n",
    "\n",
    "model.set_optimal_params(param)\n",
    "\n",
    "model.optimize(loader.X_train,loader.y_train,cv=cv,scoring='accuracy',n_iter=10)\n",
    "\n",
    "#Train model with optimal params\n",
    "model.set_model(MLPClassifier(**model.optimal_params,random_state=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Split by class, to increment by class:\n",
    "class_to_group = {1:[1,2,3,4,5,6,7],2:[8,9],3:[10,11,12,13],4:[14,15,16],5:[17,18],6:[19],7:[20,21,22]}\n",
    "X_train_merged, X_test_merged, y_train_merged, y_test_merged=loader.split_dataset_class(class_to_group)\n",
    "memory_values = []\n",
    "\n",
    "#Train model\n",
    "for X_train,y_train,X_test,y_test in (zip(X_train_merged,y_train_merged,X_test_merged,y_test_merged)):\n",
    "    mem,res=model.partial_fit_train(X_train,y_train,classes=loader.classes)\n",
    "    \n",
    "    print(\"Score accuracy group: \",model.score(X_test,y_test))\n",
    "    print(\"Score accuracy global: \",model.score(loader.X_test,loader.y_test))\n",
    "    print(\"Memory: \",np.mean(mem),\"MB\")\n",
    "    memory_values.append(np.mean(mem))\n",
    "    \n",
    "    y_pred=model.predict(loader.X_test)\n",
    "    cm = confusion_matrix(loader.y_test, y_pred)\n",
    "    ConfusionMatrixDisplay(confusion_matrix=cm).plot()\n",
    "\n",
    "model.reset_model()\n",
    "\n",
    "average_memory = np.mean(memory_values)\n",
    "print(\"Average memory usage: \", average_memory,\"MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_split_data,y_train_split_data,X_test_split_data,y_test_split_data=loader.split_dataset_data(10)\n",
    "memory_values = []\n",
    "\n",
    "for x in range(len(X_train_split_data)):\n",
    "    mem,res=model.partial_fit_train(X_train_split_data[x],y_train_split_data[x],classes=loader.classes)\n",
    "    print(\"Score accuracy batch: \",model.score(X_test_split_data[x],y_test_split_data[x]))\n",
    "    print(\"Score accuracy global: \",model.score(loader.X_test,loader.y_test))\n",
    "    print(\"Memory: \",np.mean(mem),\"MB\")\n",
    "    memory_values.append(np.mean(mem))\n",
    "\n",
    "    y_pred=model.predict(loader.X_test)\n",
    "    cm = confusion_matrix(loader.y_test, y_pred)\n",
    "    ConfusionMatrixDisplay(confusion_matrix=cm).plot()\n",
    "\n",
    "model.reset_model()\n",
    "\n",
    "average_memory = np.mean(memory_values)\n",
    "print(\"Average memory usage: \", average_memory,\"MB\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
