{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn as sk\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import os\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "from torchvision.models import resnet18,googlenet\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiple_dir_files_to_df(dirs, label):\n",
    "    df = pd.DataFrame()\n",
    "    for idx,dir in enumerate(dirs):\n",
    "        files = os.listdir(dir)\n",
    "        files = [dir + '/' + file for file in files]\n",
    "        df = pd.concat([df,pd.DataFrame({'file': files, 'label': label[idx]})])\n",
    "    return df\n",
    "\n",
    "common_path=\"Database/\"\n",
    "\n",
    "labels=[\"neutral\",\"happy\",\"sad\",\"fear\",\"angry\",\"surprise\",\"disgust\",\"Happily_Surprised\",\n",
    "\"Happily_Disgusted\",\"Sadly_Fearful\",\"Sadly_Angry\",\"Sadly_Surprised\",\"Sadly_Disgusted\",\n",
    "\"Fearfully_Angry\",\"Fearfully_Surprised\",\"Fearfully_Disgusted\",\"Angrily_Surprised\",\n",
    "\"Angrily_Disgusted\",\"Disgustedly_Surprised\",\"Appalled\",\"Hatred\",\"Awed\"]\n",
    "\n",
    "database=[common_path+label for label in labels]\n",
    "\n",
    "df = multiple_dir_files_to_df(database,np.linspace(0,len(labels)-1,len(labels)))\n",
    "X,y=df[\"file\"].tolist(),df[\"label\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définir un Dataset personnalisé\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, file_names, labels, transform=None):\n",
    "        self.file_names = file_names\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_names)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = f'{self.file_names[idx]}' \n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        label = torch.tensor(self.labels[idx], dtype=torch.float32)\n",
    "        return image, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the image transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.CenterCrop((500, 500)),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daito\\miniconda3\\envs\\ContinualLearning\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Daito\\miniconda3\\envs\\ContinualLearning\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=GoogLeNet_Weights.IMAGENET1K_V1`. You can also use `weights=GoogLeNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GoogleNet(\n",
      "  (googlenet): GoogLeNet(\n",
      "    (conv1): BasicConv2d(\n",
      "      (conv): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (maxpool1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "    (conv2): BasicConv2d(\n",
      "      (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (conv3): BasicConv2d(\n",
      "      (conv): Conv2d(64, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (maxpool2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "    (inception3a): Inception(\n",
      "      (branch1): BasicConv2d(\n",
      "        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (branch2): Sequential(\n",
      "        (0): BasicConv2d(\n",
      "          (conv): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (1): BasicConv2d(\n",
      "          (conv): Conv2d(96, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (branch3): Sequential(\n",
      "        (0): BasicConv2d(\n",
      "          (conv): Conv2d(192, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (1): BasicConv2d(\n",
      "          (conv): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (branch4): Sequential(\n",
      "        (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
      "        (1): BasicConv2d(\n",
      "          (conv): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (inception3b): Inception(\n",
      "      (branch1): BasicConv2d(\n",
      "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (branch2): Sequential(\n",
      "        (0): BasicConv2d(\n",
      "          (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (1): BasicConv2d(\n",
      "          (conv): Conv2d(128, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (branch3): Sequential(\n",
      "        (0): BasicConv2d(\n",
      "          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (1): BasicConv2d(\n",
      "          (conv): Conv2d(32, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (branch4): Sequential(\n",
      "        (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
      "        (1): BasicConv2d(\n",
      "          (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (maxpool3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "    (inception4a): Inception(\n",
      "      (branch1): BasicConv2d(\n",
      "        (conv): Conv2d(480, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (branch2): Sequential(\n",
      "        (0): BasicConv2d(\n",
      "          (conv): Conv2d(480, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (1): BasicConv2d(\n",
      "          (conv): Conv2d(96, 208, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(208, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (branch3): Sequential(\n",
      "        (0): BasicConv2d(\n",
      "          (conv): Conv2d(480, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (1): BasicConv2d(\n",
      "          (conv): Conv2d(16, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (branch4): Sequential(\n",
      "        (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
      "        (1): BasicConv2d(\n",
      "          (conv): Conv2d(480, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (inception4b): Inception(\n",
      "      (branch1): BasicConv2d(\n",
      "        (conv): Conv2d(512, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (branch2): Sequential(\n",
      "        (0): BasicConv2d(\n",
      "          (conv): Conv2d(512, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (1): BasicConv2d(\n",
      "          (conv): Conv2d(112, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (branch3): Sequential(\n",
      "        (0): BasicConv2d(\n",
      "          (conv): Conv2d(512, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (1): BasicConv2d(\n",
      "          (conv): Conv2d(24, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (branch4): Sequential(\n",
      "        (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
      "        (1): BasicConv2d(\n",
      "          (conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (inception4c): Inception(\n",
      "      (branch1): BasicConv2d(\n",
      "        (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (branch2): Sequential(\n",
      "        (0): BasicConv2d(\n",
      "          (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (1): BasicConv2d(\n",
      "          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (branch3): Sequential(\n",
      "        (0): BasicConv2d(\n",
      "          (conv): Conv2d(512, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (1): BasicConv2d(\n",
      "          (conv): Conv2d(24, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (branch4): Sequential(\n",
      "        (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
      "        (1): BasicConv2d(\n",
      "          (conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (inception4d): Identity()\n",
      "    (inception4e): Identity()\n",
      "    (maxpool4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "    (inception5a): Identity()\n",
      "    (inception5b): Identity()\n",
      "    (aux1): None\n",
      "    (aux2): None\n",
      "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "    (dropout): Dropout(p=0.2, inplace=False)\n",
      "    (fc): Linear(in_features=512, out_features=7, bias=True)\n",
      "    (Linear): Identity()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class GoogleNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.googlenet = googlenet(pretrained=True)\n",
    "        self.googlenet.fc = nn.Linear(512, 7)\n",
    "        self.googlenet.inception4d=nn.Identity()\n",
    "        self.googlenet.inception4e=nn.Identity()\n",
    "        self.googlenet.inception5a=nn.Identity()\n",
    "        self.googlenet.inception5b=nn.Identity()\n",
    "        self.googlenet.Linear=nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.googlenet(x)\n",
    "\n",
    "model= GoogleNet()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daito\\miniconda3\\envs\\ContinualLearning\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNetModel(\n",
      "  (resnet): ResNet(\n",
      "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    (layer1): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): Sequential(\n",
      "          (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (1): Dropout2d(p=0.15, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (layer2): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): Sequential(\n",
      "          (0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (1): Dropout2d(p=0.15, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (layer3): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): Sequential(\n",
      "          (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (1): Dropout2d(p=0.15, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (layer4): Identity()\n",
      "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "    (fc): Identity()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Définir le modèle ResNet\n",
    "class ResNetModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.resnet = resnet18(pretrained=True)\n",
    "        self.resnet.fc = nn.Linear(256, 7)\n",
    "        self.resnet.layer4= nn.Identity()\n",
    "        self.resnet.layer1[-1].bn2 = nn.Sequential(\n",
    "            self.resnet.layer1[-1].bn2,\n",
    "            nn.Dropout2d(p=0.15)\n",
    "        )\n",
    "\n",
    "        self.resnet.layer2[-1].bn2 = nn.Sequential(\n",
    "            self.resnet.layer2[-1].bn2,\n",
    "            nn.Dropout2d(p=0.15)\n",
    "        )\n",
    "\n",
    "        self.resnet.layer3[-1].bn2 = nn.Sequential(\n",
    "            self.resnet.layer3[-1].bn2,\n",
    "            nn.Dropout2d(p=0.15)\n",
    "        )\n",
    "        self.resnet.fc=nn.Identity()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.resnet(x)\n",
    "\n",
    "model= ResNetModel()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer les jeux de données et les chargeurs de données\n",
    "t_dataset = CustomDataset(X, y, transform)\n",
    "t_loader = DataLoader(t_dataset, batch_size=10, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 256)\n",
      "(20, 256)\n",
      "(30, 256)\n",
      "(40, 256)\n",
      "(50, 256)\n",
      "(60, 256)\n",
      "(70, 256)\n",
      "(80, 256)\n",
      "(90, 256)\n",
      "(100, 256)\n",
      "(110, 256)\n",
      "(120, 256)\n",
      "(130, 256)\n",
      "(140, 256)\n",
      "(150, 256)\n",
      "(160, 256)\n",
      "(170, 256)\n",
      "(180, 256)\n",
      "(190, 256)\n",
      "(200, 256)\n",
      "(210, 256)\n",
      "(220, 256)\n",
      "(230, 256)\n",
      "(240, 256)\n",
      "(250, 256)\n",
      "(260, 256)\n",
      "(270, 256)\n",
      "(280, 256)\n",
      "(290, 256)\n",
      "(300, 256)\n",
      "(310, 256)\n",
      "(320, 256)\n",
      "(330, 256)\n",
      "(340, 256)\n",
      "(350, 256)\n",
      "(360, 256)\n",
      "(370, 256)\n",
      "(380, 256)\n",
      "(390, 256)\n",
      "(400, 256)\n",
      "(410, 256)\n",
      "(420, 256)\n",
      "(430, 256)\n",
      "(440, 256)\n",
      "(450, 256)\n",
      "(460, 256)\n",
      "(470, 256)\n",
      "(480, 256)\n",
      "(490, 256)\n",
      "(500, 256)\n",
      "(510, 256)\n",
      "(520, 256)\n",
      "(530, 256)\n",
      "(540, 256)\n",
      "(550, 256)\n",
      "(560, 256)\n",
      "(570, 256)\n",
      "(580, 256)\n",
      "(590, 256)\n",
      "(600, 256)\n",
      "(610, 256)\n",
      "(620, 256)\n",
      "(630, 256)\n",
      "(640, 256)\n",
      "(650, 256)\n",
      "(660, 256)\n",
      "(670, 256)\n",
      "(680, 256)\n",
      "(690, 256)\n",
      "(700, 256)\n",
      "(710, 256)\n",
      "(720, 256)\n",
      "(730, 256)\n",
      "(740, 256)\n",
      "(750, 256)\n",
      "(760, 256)\n",
      "(770, 256)\n",
      "(780, 256)\n",
      "(790, 256)\n",
      "(800, 256)\n",
      "(810, 256)\n",
      "(820, 256)\n",
      "(830, 256)\n",
      "(840, 256)\n",
      "(850, 256)\n",
      "(860, 256)\n",
      "(870, 256)\n",
      "(880, 256)\n",
      "(890, 256)\n",
      "(900, 256)\n",
      "(910, 256)\n",
      "(920, 256)\n",
      "(930, 256)\n",
      "(940, 256)\n",
      "(950, 256)\n",
      "(960, 256)\n",
      "(970, 256)\n",
      "(980, 256)\n",
      "(990, 256)\n",
      "(1000, 256)\n",
      "(1010, 256)\n",
      "(1020, 256)\n",
      "(1030, 256)\n",
      "(1040, 256)\n",
      "(1050, 256)\n",
      "(1060, 256)\n",
      "(1070, 256)\n",
      "(1080, 256)\n",
      "(1090, 256)\n",
      "(1100, 256)\n",
      "(1110, 256)\n",
      "(1120, 256)\n",
      "(1130, 256)\n",
      "(1140, 256)\n",
      "(1150, 256)\n",
      "(1160, 256)\n",
      "(1170, 256)\n",
      "(1180, 256)\n",
      "(1190, 256)\n",
      "(1200, 256)\n",
      "(1210, 256)\n",
      "(1220, 256)\n",
      "(1230, 256)\n",
      "(1240, 256)\n",
      "(1250, 256)\n",
      "(1260, 256)\n",
      "(1270, 256)\n",
      "(1280, 256)\n",
      "(1290, 256)\n",
      "(1300, 256)\n",
      "(1310, 256)\n",
      "(1320, 256)\n",
      "(1330, 256)\n",
      "(1340, 256)\n",
      "(1350, 256)\n",
      "(1360, 256)\n",
      "(1370, 256)\n",
      "(1380, 256)\n",
      "(1390, 256)\n",
      "(1400, 256)\n",
      "(1410, 256)\n",
      "(1420, 256)\n",
      "(1430, 256)\n",
      "(1440, 256)\n",
      "(1450, 256)\n",
      "(1460, 256)\n",
      "(1470, 256)\n",
      "(1480, 256)\n",
      "(1490, 256)\n",
      "(1500, 256)\n",
      "(1510, 256)\n",
      "(1520, 256)\n",
      "(1530, 256)\n",
      "(1540, 256)\n",
      "(1550, 256)\n",
      "(1560, 256)\n",
      "(1570, 256)\n",
      "(1580, 256)\n",
      "(1590, 256)\n",
      "(1600, 256)\n",
      "(1610, 256)\n",
      "(1620, 256)\n",
      "(1630, 256)\n",
      "(1640, 256)\n",
      "(1650, 256)\n",
      "(1660, 256)\n",
      "(1670, 256)\n",
      "(1680, 256)\n",
      "(1690, 256)\n",
      "(1700, 256)\n",
      "(1710, 256)\n",
      "(1720, 256)\n",
      "(1730, 256)\n",
      "(1740, 256)\n",
      "(1750, 256)\n",
      "(1760, 256)\n",
      "(1770, 256)\n",
      "(1780, 256)\n",
      "(1790, 256)\n",
      "(1800, 256)\n",
      "(1810, 256)\n",
      "(1820, 256)\n",
      "(1830, 256)\n",
      "(1840, 256)\n",
      "(1850, 256)\n",
      "(1860, 256)\n",
      "(1870, 256)\n",
      "(1880, 256)\n",
      "(1890, 256)\n",
      "(1900, 256)\n",
      "(1910, 256)\n",
      "(1920, 256)\n",
      "(1930, 256)\n",
      "(1940, 256)\n",
      "(1950, 256)\n",
      "(1960, 256)\n",
      "(1970, 256)\n",
      "(1980, 256)\n",
      "(1990, 256)\n",
      "(2000, 256)\n",
      "(2010, 256)\n",
      "(2020, 256)\n",
      "(2030, 256)\n",
      "(2040, 256)\n",
      "(2050, 256)\n",
      "(2060, 256)\n",
      "(2070, 256)\n",
      "(2080, 256)\n",
      "(2090, 256)\n",
      "(2100, 256)\n",
      "(2110, 256)\n",
      "(2120, 256)\n",
      "(2130, 256)\n",
      "(2140, 256)\n",
      "(2150, 256)\n",
      "(2160, 256)\n",
      "(2170, 256)\n",
      "(2180, 256)\n",
      "(2190, 256)\n",
      "(2200, 256)\n",
      "(2210, 256)\n",
      "(2220, 256)\n",
      "(2230, 256)\n",
      "(2240, 256)\n",
      "(2250, 256)\n",
      "(2260, 256)\n",
      "(2270, 256)\n",
      "(2280, 256)\n",
      "(2290, 256)\n",
      "(2300, 256)\n",
      "(2310, 256)\n",
      "(2320, 256)\n",
      "(2330, 256)\n",
      "(2340, 256)\n",
      "(2350, 256)\n",
      "(2360, 256)\n",
      "(2370, 256)\n",
      "(2380, 256)\n",
      "(2390, 256)\n",
      "(2400, 256)\n",
      "(2410, 256)\n",
      "(2420, 256)\n",
      "(2430, 256)\n",
      "(2440, 256)\n",
      "(2450, 256)\n",
      "(2460, 256)\n",
      "(2470, 256)\n",
      "(2480, 256)\n",
      "(2490, 256)\n",
      "(2500, 256)\n",
      "(2510, 256)\n",
      "(2520, 256)\n",
      "(2530, 256)\n",
      "(2540, 256)\n",
      "(2550, 256)\n",
      "(2560, 256)\n",
      "(2570, 256)\n",
      "(2580, 256)\n",
      "(2590, 256)\n",
      "(2600, 256)\n",
      "(2610, 256)\n",
      "(2620, 256)\n",
      "(2630, 256)\n",
      "(2640, 256)\n",
      "(2650, 256)\n",
      "(2660, 256)\n",
      "(2670, 256)\n",
      "(2680, 256)\n",
      "(2690, 256)\n",
      "(2700, 256)\n",
      "(2710, 256)\n",
      "(2720, 256)\n",
      "(2730, 256)\n",
      "(2740, 256)\n",
      "(2750, 256)\n",
      "(2760, 256)\n",
      "(2770, 256)\n",
      "(2780, 256)\n",
      "(2790, 256)\n",
      "(2800, 256)\n",
      "(2810, 256)\n",
      "(2820, 256)\n",
      "(2830, 256)\n",
      "(2840, 256)\n",
      "(2850, 256)\n",
      "(2860, 256)\n",
      "(2870, 256)\n",
      "(2880, 256)\n",
      "(2890, 256)\n",
      "(2900, 256)\n",
      "(2910, 256)\n",
      "(2920, 256)\n",
      "(2930, 256)\n",
      "(2940, 256)\n",
      "(2950, 256)\n",
      "(2960, 256)\n",
      "(2970, 256)\n",
      "(2980, 256)\n",
      "(2990, 256)\n",
      "(3000, 256)\n",
      "(3010, 256)\n",
      "(3020, 256)\n",
      "(3030, 256)\n",
      "(3040, 256)\n",
      "(3050, 256)\n",
      "(3060, 256)\n",
      "(3070, 256)\n",
      "(3080, 256)\n",
      "(3090, 256)\n",
      "(3100, 256)\n",
      "(3110, 256)\n",
      "(3120, 256)\n",
      "(3130, 256)\n",
      "(3140, 256)\n",
      "(3150, 256)\n",
      "(3160, 256)\n",
      "(3170, 256)\n",
      "(3180, 256)\n",
      "(3190, 256)\n",
      "(3200, 256)\n",
      "(3210, 256)\n",
      "(3220, 256)\n",
      "(3230, 256)\n",
      "(3240, 256)\n",
      "(3250, 256)\n",
      "(3260, 256)\n",
      "(3270, 256)\n",
      "(3280, 256)\n",
      "(3290, 256)\n",
      "(3300, 256)\n",
      "(3310, 256)\n",
      "(3320, 256)\n",
      "(3330, 256)\n",
      "(3340, 256)\n",
      "(3350, 256)\n",
      "(3360, 256)\n",
      "(3370, 256)\n",
      "(3380, 256)\n",
      "(3390, 256)\n",
      "(3400, 256)\n",
      "(3410, 256)\n",
      "(3420, 256)\n",
      "(3430, 256)\n",
      "(3440, 256)\n",
      "(3450, 256)\n",
      "(3460, 256)\n",
      "(3470, 256)\n",
      "(3480, 256)\n",
      "(3490, 256)\n",
      "(3500, 256)\n",
      "(3510, 256)\n",
      "(3520, 256)\n",
      "(3530, 256)\n",
      "(3540, 256)\n",
      "(3550, 256)\n",
      "(3560, 256)\n",
      "(3570, 256)\n",
      "(3580, 256)\n",
      "(3590, 256)\n",
      "(3600, 256)\n",
      "(3610, 256)\n",
      "(3620, 256)\n",
      "(3630, 256)\n",
      "(3640, 256)\n",
      "(3650, 256)\n",
      "(3660, 256)\n",
      "(3670, 256)\n",
      "(3680, 256)\n",
      "(3690, 256)\n",
      "(3700, 256)\n",
      "(3710, 256)\n",
      "(3720, 256)\n",
      "(3730, 256)\n",
      "(3740, 256)\n",
      "(3750, 256)\n",
      "(3760, 256)\n",
      "(3770, 256)\n",
      "(3780, 256)\n",
      "(3790, 256)\n",
      "(3800, 256)\n",
      "(3810, 256)\n",
      "(3820, 256)\n",
      "(3830, 256)\n",
      "(3840, 256)\n",
      "(3850, 256)\n",
      "(3860, 256)\n",
      "(3870, 256)\n",
      "(3880, 256)\n",
      "(3890, 256)\n",
      "(3900, 256)\n",
      "(3910, 256)\n",
      "(3920, 256)\n",
      "(3930, 256)\n",
      "(3940, 256)\n",
      "(3950, 256)\n",
      "(3960, 256)\n",
      "(3970, 256)\n",
      "(3980, 256)\n",
      "(3990, 256)\n",
      "(4000, 256)\n",
      "(4010, 256)\n",
      "(4020, 256)\n",
      "(4030, 256)\n",
      "(4040, 256)\n",
      "(4050, 256)\n",
      "(4060, 256)\n",
      "(4070, 256)\n",
      "(4080, 256)\n",
      "(4090, 256)\n",
      "(4100, 256)\n",
      "(4110, 256)\n",
      "(4120, 256)\n",
      "(4130, 256)\n",
      "(4140, 256)\n",
      "(4150, 256)\n",
      "(4160, 256)\n",
      "(4170, 256)\n",
      "(4180, 256)\n",
      "(4190, 256)\n",
      "(4200, 256)\n",
      "(4210, 256)\n",
      "(4220, 256)\n",
      "(4230, 256)\n",
      "(4240, 256)\n",
      "(4250, 256)\n",
      "(4260, 256)\n",
      "(4270, 256)\n",
      "(4280, 256)\n",
      "(4290, 256)\n",
      "(4300, 256)\n",
      "(4310, 256)\n",
      "(4320, 256)\n",
      "(4330, 256)\n",
      "(4340, 256)\n",
      "(4350, 256)\n",
      "(4360, 256)\n",
      "(4370, 256)\n",
      "(4380, 256)\n",
      "(4390, 256)\n",
      "(4400, 256)\n",
      "(4410, 256)\n",
      "(4420, 256)\n",
      "(4430, 256)\n",
      "(4440, 256)\n",
      "(4450, 256)\n",
      "(4460, 256)\n",
      "(4470, 256)\n",
      "(4480, 256)\n",
      "(4490, 256)\n",
      "(4500, 256)\n",
      "(4510, 256)\n",
      "(4520, 256)\n",
      "(4530, 256)\n",
      "(4540, 256)\n",
      "(4550, 256)\n",
      "(4560, 256)\n",
      "(4570, 256)\n",
      "(4580, 256)\n",
      "(4590, 256)\n",
      "(4600, 256)\n",
      "(4610, 256)\n",
      "(4620, 256)\n",
      "(4630, 256)\n",
      "(4640, 256)\n",
      "(4650, 256)\n",
      "(4660, 256)\n",
      "(4670, 256)\n",
      "(4680, 256)\n",
      "(4690, 256)\n",
      "(4700, 256)\n",
      "(4710, 256)\n",
      "(4720, 256)\n",
      "(4730, 256)\n",
      "(4740, 256)\n",
      "(4750, 256)\n",
      "(4760, 256)\n",
      "(4770, 256)\n",
      "(4780, 256)\n",
      "(4790, 256)\n",
      "(4800, 256)\n",
      "(4810, 256)\n",
      "(4820, 256)\n",
      "(4830, 256)\n",
      "(4840, 256)\n",
      "(4850, 256)\n",
      "(4860, 256)\n",
      "(4870, 256)\n",
      "(4880, 256)\n",
      "(4890, 256)\n",
      "(4900, 256)\n",
      "(4910, 256)\n",
      "(4920, 256)\n",
      "(4930, 256)\n",
      "(4940, 256)\n",
      "(4950, 256)\n",
      "(4960, 256)\n",
      "(4970, 256)\n",
      "(4980, 256)\n",
      "(4990, 256)\n",
      "(5000, 256)\n",
      "(5010, 256)\n",
      "(5020, 256)\n",
      "(5030, 256)\n",
      "(5040, 256)\n",
      "(5050, 256)\n",
      "(5060, 256)\n"
     ]
    }
   ],
   "source": [
    "#Features extraction\n",
    "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "pretrained_model =\"./resnet_18_pretrained_7_emo_19.pth\"\n",
    "model = ResNetModel()  \n",
    "model.load_state_dict(torch.load(pretrained_model, map_location=torch.device('cuda' if torch.cuda.is_available() else 'cpu')),strict=False)\n",
    "model.eval()\n",
    "df=pd.DataFrame()\n",
    "\n",
    "for i, (x, y) in enumerate(t_loader):\n",
    "    x = x.to(device)\n",
    "    y = y.to(device)\n",
    "    with torch.no_grad():\n",
    "        output = model(x)\n",
    "        df=pd.concat([df,pd.DataFrame(output.cpu().numpy())])\n",
    "        print(df.shape)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"features_resnet.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        0         1         2         3         4         5         6    \\\n",
      "0  0.058971  0.626277  0.107093  0.670639  0.685376  0.672881  0.541003   \n",
      "1  0.293999  0.680076  0.070964  0.704674  0.800976  0.759914  0.789037   \n",
      "2  0.026243  0.493064  0.071549  0.598101  0.668996  0.798525  0.383728   \n",
      "3  0.264287  0.605679  0.043540  0.597127  0.845713  0.770380  0.757597   \n",
      "4  0.049339  0.610061  0.145537  0.661091  0.692952  0.739890  0.485597   \n",
      "\n",
      "        7         8         9    ...       246       247       248       249  \\\n",
      "0  0.021652  0.078406  0.713660  ...  0.555141  0.029386  0.000524  0.013478   \n",
      "1  0.083484  0.022216  0.857469  ...  0.636875  0.287480  0.177322  0.007050   \n",
      "2  0.031116  0.151202  0.682578  ...  0.351739  0.033807  0.009727  0.029941   \n",
      "3  0.022491  0.014760  0.863484  ...  0.605871  0.238986  0.094417  0.003430   \n",
      "4  0.096431  0.157701  0.787261  ...  0.477616  0.060900  0.035032  0.053462   \n",
      "\n",
      "        250       251       252       253       254       255  \n",
      "0  0.039791  0.646996  0.023738  0.121163  0.635599  0.134817  \n",
      "1  0.097236  0.761347  0.043558  0.213288  0.623736  0.439586  \n",
      "2  0.064688  0.488825  0.030042  0.060805  0.451506  0.112139  \n",
      "3  0.077564  0.670703  0.016591  0.164107  0.559405  0.369584  \n",
      "4  0.054304  0.583125  0.083556  0.085232  0.604767  0.216669  \n",
      "\n",
      "[5 rows x 256 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ContinualLearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
